{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tout d'abord, nous importons les bibliothèques permettant de récupérer les données. La bliothèque requests permet d'envoyer des requêtes à des sites web, bs4 permet d'analyser et extraire des données de documents HTML et donc de sites internet, re permet de rechercher des expressions régulières (regex) dans du texte, pandas permet de manipuler des bases de données et rapidfuzz fournit des outils pour comparer des chaînes de caractères."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import re\n",
    "import pandas as pd\n",
    "from rapidfuzz import fuzz\n",
    "import s3fs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On cherche tout d'abord à confectionner une table avec les informations sur le livre et le numéro d'index auquel il correspond. Cette base sera ensuite donnée à l'API pour qu'elle donne un ou plusieurs thème à chaque texte. \n",
    "La cellule ci-dessous permet de récupérer le texte de la page \"gutindex.all\", qui associe à chaque oouvrage un numéro d'index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL du fichier d'index des textes\n",
    "url_liste_textes = \"https://www.gutenberg.org/dirs/GUTINDEX.ALL.iso-8859-1.txt\"\n",
    "\n",
    "# Téléchargement du fichier d'index\n",
    "request_liste_textes = requests.get(url_liste_textes).content\n",
    "page = bs4.BeautifulSoup(request_liste_textes, \"lxml\")\n",
    "body = page.find(\"body\")\n",
    "index_texte = body.get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toujours dans l'optique de créer une table avec les informations sur le texte dans une colonne et l'index dans l'autre, on ne souhaite garder que le texte correspondant aux informations et à l'index. \n",
    "On utilise pour ce faire les balises de début et de fin de l'index puis on supprime les quelques lignes inutiles qui donnent des informations sur le contenu de l'index après avoir converti le texte en une liste de lignes pour faciliter le traitement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chercher les indices des marqueurs \"<===LISTINGS===>\" et \"<==End of GUTINDEX.ALL==>\"\n",
    "start_marker = \"<===LISTINGS===>\"\n",
    "end_marker = \"<==End of GUTINDEX.ALL==>\"\n",
    "start_index = index_texte.find(start_marker)\n",
    "end_index = index_texte.find(end_marker)\n",
    "\n",
    "# Extraire le texte entre les marqueurs\n",
    "texte_extrait = index_texte[start_index + len(start_marker):end_index].strip()\n",
    "texte_extrait_lignes = texte_extrait.splitlines()\n",
    "\n",
    "# Filtrer les lignes pertinentes\n",
    "texte_extrait_lignes_trie = texte_extrait_lignes[10:len(texte_extrait_lignes)-1]\n",
    "texte_complet = '\\n'.join(texte_extrait_lignes_trie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il nous faut donc maintenant séparer le texte en deux parties, l'une contenant les informations sur l'oeuvre (titre, auteur, date, langue de l'oeuvre...) et l'autre le numéro d'index.\n",
    "La cellule ci-dessous, après avoir divisé le texte en oeuvres, créé une liste d'oeuvre avec description (contenant les informations sur l'oeuvre) et index séparés. La première utilisation du regex dans la boucle permet d'extraire l'index tandis que la deuxième permet de retirer l'index et les espaces superflus pour ne garder que le texte pour la colonne \"Description\". On convertit enfin la liste en dataframe pour la manipuler plus efficacement et on ne garde que les textes en français."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diviser le texte en oeuvres\n",
    "oeuvres = re.split(r'(?=\\n{2,})', texte_complet.strip())\n",
    "\n",
    "# Extraire les descriptions et indices\n",
    "# Liste pour stocker les données extraites\n",
    "data = []\n",
    "for oeuvre in oeuvres:\n",
    "    # Trouver l'index dans l'oeuvre\n",
    "    match_index = re.search(r'(?<=\\s\\s)([\\d]+?[A-Z]?)(?=\\n)', oeuvre)\n",
    "    index = match_index.group(1) if match_index else None\n",
    "\n",
    "    # Nettoyer le texte de l'oeuvre\n",
    "    description = re.sub(r'(?<=\\s\\s)([\\d]+?[A-Z]?)(?=\\n)', '', oeuvre).strip()\n",
    "\n",
    "    # Ajouter les données\n",
    "    data.append({\"Description\": description, \"Index\": index})\n",
    "\n",
    "# Convertir les données en DataFrame\n",
    "df_livres = pd.DataFrame(data)\n",
    "df_livres_fr = df_livres[df_livres[\"Description\"].str.contains(r\"\\[Language: French\\]\", na=False)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin que l'API nous donne bien des thèmes pour les textes envoyés, nous avons fait le choix, après quellques essais, de nous restreindre à ceux d'auteurs célèbres. Nous avons donc réalisé une liste d'auteurs célèbres des 17\n",
    "La cellule ci-dessous ne garde que les ouvrages dont l'auteur est dans la liste. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_livres_fr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m auteurs_join \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mmap\u001b[39m(re\u001b[38;5;241m.\u001b[39mescape, auteurs))\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Filtrer les lignes qui contiennent au moins un des auteurs\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m df_livres_fr_filtré \u001b[38;5;241m=\u001b[39m \u001b[43mdf_livres_fr\u001b[49m[df_livres_fr[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDescription\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(auteurs_join, na\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)]\n\u001b[1;32m     28\u001b[0m fs \u001b[38;5;241m=\u001b[39m s3fs\u001b[38;5;241m.\u001b[39mS3FileSystem(client_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mendpoint_url\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://minio.lab.sspcloud.fr\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[1;32m     30\u001b[0m MY_BUCKET \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marnaudbrrt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_livres_fr' is not defined"
     ]
    }
   ],
   "source": [
    "# List of French Writers abritrarily defined and chosen in the 17th, 18th and 19th century\n",
    "auteurs = [\n",
    "    # 17th century\n",
    "    \"Honoré d'Urfé\", \"Madeleine de Scudéry\", \"Paul Scarron\", \"Jean de La Fontaine\",\n",
    "    \"Madame de Lafayette\", \"Charles Sorel\", \"Tristan L'Hermite\", \"François de Salignac de La Mothe-Fénelon\",\n",
    "    \"Savinien de Cyrano de Bergerac\",\n",
    "    \n",
    "    # 18th century\n",
    "    \"Montesquieu\", \"Voltaire\", \"Jean-Jacques Rousseau\", \"Denis Diderot\", \"Marivaux\",\n",
    "    \"Abbé Prévost\", \"Pierre Choderlos de Laclos\", \"Beaumarchais\", \n",
    "    \n",
    "    # 19th century\n",
    "    \"Honoré de Balzac\", \"Victor Hugo\", \"Alexandre Dumas\", \"Gustave Flaubert\", \"Émile Zola\",\n",
    "    \"Stendhal\", \"Alfred de Musset\", \"George Sand\", \"Jules Verne\", \"Alphonse Daudet\",\n",
    "    \"Théophile Gautier\", \"Edmond de Goncourt\",\n",
    "    \"Joris-Karl Huysmans\", \"Octave Mirbeau\", \n",
    "    \"Prosper Mérimée\", \"Eugène Sue\", \"Charles Nodier\",\n",
    "    \"Gaston Leroux\", \"François-René de Chateaubriand\", \"Anatole France\", \"Gustave Flaubert\", \"Alfred Jarry\",\n",
    "    \"Guy de Maupassant\", \"Romain Rolland\", \"Alfred Séguin\", \"Alfred de Vigny\", \"Paul de Kock\"\n",
    "\n",
    "]\n",
    "\n",
    "#On créé une expression réulière que signifie \"ou\" pour l'utiliser ensuite\n",
    "auteurs_join = \"|\".join(map(re.escape, auteurs))\n",
    "# Filtrer les lignes qui contiennent au moins un des auteurs\n",
    "df_livres_fr_filtré = df_livres_fr[df_livres_fr[\"Description\"].str.contains(auteurs_join, na=False)]\n",
    "\n",
    "fs = s3fs.S3FileSystem(client_kwargs={\"endpoint_url\": \"https://minio.lab.sspcloud.fr\"})\n",
    "\n",
    "MY_BUCKET = \"arnaudbrrt\"\n",
    "fs.ls(MY_BUCKET) \n",
    "FILE_PATH_OUT_S3 = f\"{MY_BUCKET}/Data_libroguessr/livres_fr_triés.csv\"\n",
    "\n",
    "with fs.open(FILE_PATH_OUT_S3, \"w\") as file_out:\n",
    "    df_livres_fr_filtré.to_csv(file_out, index =False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
